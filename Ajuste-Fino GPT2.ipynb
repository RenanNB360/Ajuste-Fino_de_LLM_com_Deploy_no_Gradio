{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a929e9a-4e3a-46d6-b34e-b70d5a00a7e8",
   "metadata": {},
   "source": [
    "# Carregamento dos Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16588de7-2254-4514-82a3-f8dcffc3d401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_CPP_MIN_LOG_LEVEL=3\n"
     ]
    }
   ],
   "source": [
    "%env TF_CPP_MIN_LOG_LEVEL = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afbf3f7d-2090-4e54-94b4-dd683d568933",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renan/anaconda3/envs/nlp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import accelerate\n",
    "import transformers\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from accelerate import Accelerator\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, GPT2Tokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fcc834-59cd-4890-bb4f-1d5d0f7018af",
   "metadata": {},
   "source": [
    "# Carregando o LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79cae495-4408-457d-a7ba-b02ba9b468df",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 13\n",
    "sequence_length = 4\n",
    "result_length = 2\n",
    "context_length = sequence_length + result_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e43358c9-a6b7-4eeb-ba8e-225ed0521025",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('gpt2',\n",
    "                                    vocab_size = vocab_size,\n",
    "                                    n_ctx = context_length,\n",
    "                                    n_head = 4,\n",
    "                                    n_layer = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a14696f0-c321-4148-a149-9331a2321096",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa9333b4-06b2-4d70-9b1e-e54b6ecf331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_tamanho_modelo(model):\n",
    "    return sum(t.numel() for t in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61d76ff0-74f2-4cf8-a752-65898f6bdd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do Modelo: 15.0M parâmetros\n"
     ]
    }
   ],
   "source": [
    "print(f'Tamanho do Modelo: {calcula_tamanho_modelo(model) / 1000 ** 2:.1f}M parâmetros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59bc30ba-7c07-439f-ac42-533131dd2296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09654b6c-c41a-43cf-9452-d93527044ebd",
   "metadata": {},
   "source": [
    "# Criando Tokenizador Personalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a2e199f-1eb0-4380-8979-c82dcc5bf5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "\n",
    "    def __init__(self, numbers_qty = 10):\n",
    "        vocab = ['+', '=', '-1', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "        self.numbers_qty = numbers_qty\n",
    "        self.pad_token = '-1'\n",
    "        self.encoder = {str(v):i for i, v in enumerate(vocab)}\n",
    "        self.decoder = {i:str(v) for i, v in enumerate(vocab)}\n",
    "        self.pad_token_id = self.encoder[self.pad_token]\n",
    "\n",
    "    def decode(self, token_ids):\n",
    "        return ' '.join(self.decoder[t] for t in token_ids)\n",
    "\n",
    "    def __call__(self, text):\n",
    "        return [self.encoder[t] for t in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4108409e-c054-478f-b23f-165aa9edd191",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8abb1fc-30df-481f-83cc-bc9d46260a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '+',\n",
       " 1: '=',\n",
       " 2: '-1',\n",
       " 3: '0',\n",
       " 4: '1',\n",
       " 5: '2',\n",
       " 6: '3',\n",
       " 7: '4',\n",
       " 8: '5',\n",
       " 9: '6',\n",
       " 10: '7',\n",
       " 11: '8',\n",
       " 12: '9'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3480655-5b7a-4f2b-bab2-a0bc753098b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 0, 4, 1, 5]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('1 + 1 = 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6ecf82a-5f0d-43da-b8f3-c985d51e052c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'14'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m9 + 5 = 14\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m, in \u001b[0;36mTokenizer.__call__\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m text\u001b[38;5;241m.\u001b[39msplit()]\n",
      "\u001b[0;31mKeyError\u001b[0m: '14'"
     ]
    }
   ],
   "source": [
    "tokenizer('9 + 5 = 14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "602b758d-066d-40d1-8d0e-e420e5fb7cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 0, 8, 1, 4, 7]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('9 + 5 = 1 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e805880-e738-4bfa-b833-71435a8b9cb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'19'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m19 + 5 = 2 4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m, in \u001b[0;36mTokenizer.__call__\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m text\u001b[38;5;241m.\u001b[39msplit()]\n",
      "\u001b[0;31mKeyError\u001b[0m: '19'"
     ]
    }
   ],
   "source": [
    "tokenizer('19 + 5 = 2 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516135fb-d1d0-48c3-813e-b6e5b84cd39f",
   "metadata": {},
   "source": [
    "# Organizando o Formato dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2950e350-8323-47c8-b8db-f6985a245288",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrganizaDataset(Dataset):\n",
    "\n",
    "    def __init__(self, split, length = 6):\n",
    "        assert split in {'treino', 'teste'}\n",
    "        self.split = split\n",
    "        self.length = length\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1000000\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        available_numbers = [int(n) for n in tokenizer.decoder.values() if n != tokenizer.pad_token and str(n).isnumeric()]\n",
    "        inp = torch.tensor(np.random.choice(available_numbers, size = result_length))\n",
    "        sol = torch.tensor([int(i) for i in str(inp.sum().item())])\n",
    "        sol = torch.nn.functional.pad(sol, (1 if sol.size()[0] == 1 else 0,0), 'constant', 0)\n",
    "        cat = torch.cat((inp, sol), dim = 0)\n",
    "        x = cat[:-1].clone()\n",
    "        y = cat[1:].clone()\n",
    "        y[:1] = int(tokenizer.pad_token)\n",
    "        x = str(x[0].item()) + ' + ' + str(x[1].item()) + ' = ' + str(x[2].item())\n",
    "        y = '-1 ' + str(y[0].item()) + ' -1 ' + str(y[1].item()) + ' ' + str(y[2].item())\n",
    "        tokenized_input = tokenizer(x)\n",
    "        tokenized_output = tokenizer(y)\n",
    "\n",
    "        return torch.tensor(tokenized_input), torch.tensor(tokenized_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ce3756-370f-46ba-9c73-a557fe2e3bd0",
   "metadata": {},
   "source": [
    "# Criando os Datasets de Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "578d3480-1de3-4174-b4c6-b913cf11bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_treino = OrganizaDataset('treino', length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34760f99-7ae7-4bc6-af78-598e5ec583fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_teste = OrganizaDataset('teste', length= sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e247919f-8385-4019-a5ea-d15d757b388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dataset_treino[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e65bd02d-7b94-44ff-8390-a7d3a085d55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5,  0, 12,  1,  4])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d897098a-888a-4439-a6ae-2f8edb59a023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 4, 4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6fed4bde-2c02-4603-b327-416f735b375e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 9 = 1\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(x.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a19e5a51-8354-4609-a7cd-457765915a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 -1 -1 1 1\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(y.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047753e9-fe0d-4383-97c9-28d659559eb8",
   "metadata": {},
   "source": [
    "# Criando o Loop de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8c8b36b-22d1-4ccb-88c9-e51ce8d046a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c55242cf-88b9-4002-8172-b9bcc3653d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cdf7d074-f1f3-4ec5-a7cf-0173bc6d5e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.utils.data.DataLoader(dataset_treino, shuffle = True, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c78452bc-2a1d-46f8-98b9-2d905c596cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45781d10-7136-4307-bb8b-cca93850ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, data = accelerator.prepare(model, optimizer, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dee158a9-ca0d-4b44-9d08-5919757adf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(13, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-1): 2 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=13, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e83e1ad-9ddd-4d07-b7ce-c378fef90539",
   "metadata": {},
   "source": [
    "# Treinando o LLM (Ajuste Fino) com Nossos Próprios Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82644425-1439-4a73-a297-6355e862d4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando o Ajuste Fino do LLM... Seja Paciente e Aguarde!\n",
      "\n",
      "Epoch: 1 / 2 -- Erro: 0.03602537512779236\n",
      "\n",
      "Epoch: 2 / 2 -- Erro: 0.029243573546409607\n",
      "\n",
      "Ajuste Fino do LLM Concluído com Sucesso.\n",
      "\n",
      "CPU times: user 9min 27s, sys: 1.42 s, total: 9min 28s\n",
      "Wall time: 9min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('\\nIniciando o Ajuste Fino do LLM... Seja Paciente e Aguarde!')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for source, targets in data:\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(model(source).logits.flatten(end_dim = 1),\n",
    "                               targets.flatten(end_dim = 1),\n",
    "                               ignore_index= tokenizer.pad_token_id)\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        loss = F.cross_entropy(model(source).logits.flatten(end_dim = 1),\n",
    "                               targets.flatten(end_dim = 1),\n",
    "                               ignore_index = tokenizer.pad_token_id)\n",
    "\n",
    "    print(f'\\nEpoch: {epoch+1} / {num_epochs} -- Erro: {loss.item()}')\n",
    "\n",
    "print('\\nAjuste Fino do LLM Concluído com Sucesso.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3181a9d2-1b16-4b8c-af91-f60245ba992d",
   "metadata": {},
   "source": [
    "# Avaliação do LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "52c2303f-d7d1-4da1-9eb9-6c0978b06d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def faz_previsao(entrada, solution_length = 6, model = model):\n",
    "\n",
    "    model.eval()\n",
    "    entrada = torch.tensor(tokenizer(entrada))\n",
    "    entrada = entrada.to(accelerator.device)\n",
    "    solution = []\n",
    "    \n",
    "    for i in range(solution_length):\n",
    "        saida = model(entrada)\n",
    "        predicted = saida.logits[-1].argmax()\n",
    "        entrada = torch.cat((entrada, predicted.unsqueeze(0)), dim = 0)\n",
    "        solution.append(predicted.cpu().item())\n",
    "\n",
    "    return tokenizer.decode(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a347eae8-1759-42f5-8b93-ef5640621dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avalia_modelo(num_samples = 1000, log = False):\n",
    "\n",
    "    correct = 0\n",
    "    for i in range(num_samples):\n",
    "        entrada, target = dataset_teste[i]\n",
    "        entrada = entrada.cpu().numpy()\n",
    "        target = target.cpu().numpy()\n",
    "        entrada = tokenizer.decode(entrada[:sequence_length])\n",
    "        target = tokenizer.decode(target[sequence_length-1:])\n",
    "        predicted = faz_previsao(entrada, solution_length = result_length, model = model)\n",
    "\n",
    "        if target == predicted:\n",
    "            correct += 1\n",
    "            if log:\n",
    "                print(f'Acerto do Modelo: Input: {entrada} Target: {target} Previsão: {predicted}')\n",
    "\n",
    "        else:\n",
    "            if log:\n",
    "              print(f'Erro do Modelo: Input: {entrada} Target: {target} Previsão: {predicted}')\n",
    "\n",
    "    print(f'\\nAcurácia: {correct/num_samples}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "58f4a47b-2724-49bd-8cfd-ccc1fe85620d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acerto do Modelo: Input: 7 + 1 = Target: 0 8 Previsão: 0 8\n",
      "Acerto do Modelo: Input: 7 + 6 = Target: 1 3 Previsão: 1 3\n",
      "Acerto do Modelo: Input: 3 + 7 = Target: 1 0 Previsão: 1 0\n",
      "Acerto do Modelo: Input: 3 + 4 = Target: 0 7 Previsão: 0 7\n",
      "Acerto do Modelo: Input: 6 + 7 = Target: 1 3 Previsão: 1 3\n",
      "Acerto do Modelo: Input: 5 + 5 = Target: 1 0 Previsão: 1 0\n",
      "Acerto do Modelo: Input: 2 + 5 = Target: 0 7 Previsão: 0 7\n",
      "Acerto do Modelo: Input: 5 + 4 = Target: 0 9 Previsão: 0 9\n",
      "Acerto do Modelo: Input: 0 + 7 = Target: 0 7 Previsão: 0 7\n",
      "Acerto do Modelo: Input: 2 + 1 = Target: 0 3 Previsão: 0 3\n",
      "\n",
      "Acurácia: 1.0\n"
     ]
    }
   ],
   "source": [
    "avalia_modelo(num_samples= 10, log = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "532b981b-4e9d-43fd-9ec8-559b1cb77466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Acurácia: 1.0\n"
     ]
    }
   ],
   "source": [
    "avalia_modelo(num_samples= 1000, log= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cbc902ab-5939-4c2b-a130-cbc21d4e25d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47033c2c-4445-4010-a6ac-16b00e971903",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('llm/llm_final')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
